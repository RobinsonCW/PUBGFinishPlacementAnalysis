---
title: "Naive Bayes"
author: "Chance Robinson"
date: "11/30/2019"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exploratory Data Analysis

## Library Imports


```{r library-imports, quietely=TRUE, warn.conflicts=FALSE}
library(tidyverse)
# Naive Bayes
library(naivebayes)
# downSample
library(caret)
```



## Load the CSV Data

```{r load-data}
data <- read.csv("../../../data/pubg_solo_game_types.csv", stringsAsFactors=FALSE)

```


```{r head-data}
head(data)
```

## Remove Missing Values

```{r data-missing}
# remove the row with no winPlacePerc   
data <- data[!data$Id == 'f70c74418bb064',]
```



## Specify Model Columns of Interest

```{r data-significant-columns}
cols_to_keep = c("walkDistance", "killPlace", "boosts", "weaponsAcquired", "damageDealt", "heals", "kills", "top.10")

cols_to_remove = c("Id", "groupId", "matchId", "matchType", "DBNOs")

head(data[cols_to_keep])


```


## Prepare Dataframe

```{r data-preparation}
data.mod <- data %>%
  select(-cols_to_remove) %>%
  mutate(top.10 = factor(top.10, labels = c("No", "Yes"))) 

summary(data.mod)

# str(data.mod)

```


## Naive Bayes Train / Test Split

```{r nb-train-test-split}

set.seed(1234)
split.perc = .70

train.indices = sample(1:dim(data.mod)[1],round(split.perc * dim(data.mod)[1]))

train = data.mod[train.indices,]
test = data.mod[-train.indices,]


train <- downSample(train, train$top.10, list = FALSE)
train$Class <- NULL


model.nb.train <- naive_bayes(top.10 ~ ., data = train, laplace = TRUE, usekernel = TRUE)

# p <- predict(model.nb, train, type = 'prob')
# cbind(p, train)

p1 <- predict(model.nb.train, train)
p2 <- predict(model.nb.train, test)
# (tab1 <- table(p1, data.mod.nb$Attrition))

```



## Naive Bayes Performance

### Train
```{r nb-performance-train}

confusionMatrix(data=p1,  
                reference=train$top.10, "Yes")

```

### Test
```{r nb-performance-test}


confusionMatrix(data=p2,  
                reference=test$top.10, "Yes")

```





